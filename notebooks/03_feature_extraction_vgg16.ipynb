{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'label_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     20\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlabel_tools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'label_tools'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import permute,avg_pool1d\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import label_tools as lt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 files are: ['CFB184_ortho_mask_0038_10_preprocessed.png', 'CFB125_ortho_mask_0104_12_preprocessed.png', 'CFB184_ortho_mask_0138_12_preprocessed.png', 'CFB167_ortho_mask_0029_12_preprocessed.png', 'CFB133_ortho_mask_0203_10_preprocessed.png', 'CFB151_ortho_mask_0041_12_preprocessed.png', 'CFB184_ortho_mask_0252_10_preprocessed.png', 'CFB151_ortho_mask_0050_12_preprocessed.png', 'CFB125_ortho_mask_0053_4_preprocessed.png', 'CFB167_ortho_mask_0198_12_preprocessed.png']\n"
     ]
    }
   ],
   "source": [
    "# load pre processed files\n",
    "imgs_path = Path('/home/richard/data/Schiefer/combine/preprocessed_224_clipped_pred_polygon_1126/')\n",
    "assert imgs_path.is_dir()\n",
    "files = sorted(imgs_path.glob('*.png'))\n",
    "\n",
    "randomizer = np.random.RandomState(seed=99834)\n",
    "randomizer.shuffle(files)\n",
    "\n",
    "assert len(files) == 1126 # all files are found\n",
    "print(\"First 10 files are: {}\".format([x.name for x in files[:10]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def alter_image(img_name):\n",
    "    image = cv2.imread(str(img_name))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = normalize(to_tensor(image)).unsqueeze(0)\n",
    "    image_tensor = image_tensor.reshape(1,3,224,224)\n",
    "    return image_tensor\n",
    "\n",
    "def load_images_as_tensors(paths):\n",
    "    images = [alter_image(image) for image in paths]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = load_images_as_tensors(files)\n",
    "assert len(image_tensors) == 1126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting labels from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 labels: ['10', '12', '12', '12', '10', '12', '10', '12', '4', '12']\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(files): return [filename.stem.split('_')[4] for filename in files]\n",
    "labels = extract_labels(files)\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 labels: ['Abies_alba', 'Picea_abies', 'Picea_abies', 'Picea_abies', 'Abies_alba', 'Picea_abies', 'Abies_alba', 'Picea_abies', 'Fagus_sylvatica', 'Picea_abies']\n"
     ]
    }
   ],
   "source": [
    "# change labels from number to species (of collab)\n",
    "update = {\n",
    "    '4':'Fagus_sylvatica',\n",
    "    '5':'Fraxinus_excelsior',\n",
    "    '6':'Quercus_spec',\n",
    "    '8':'deadwood',\n",
    "    '10':'Abies_alba',\n",
    "    '11':'Larix_decidua',\n",
    "    '12':'Picea_abies',\n",
    "    '13':'Pinus_sylvestris',\n",
    "    '14':'Pseudotsuga_menziesii'\n",
    "}\n",
    "\n",
    "updated_labels = (pd.Series(labels)).map(update)\n",
    "species_labels = list(updated_labels)\n",
    "labels = species_labels\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding\n",
    "\n",
    "Standardize encodings of labels to make analysis easier afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encodings: {'Abies_alba': 0, 'deadwood': 1, 'Fagus_sylvatica': 2, 'Fraxinus_excelsior': 3, 'Larix_decidua': 4, 'Picea_abies': 5, 'Pinus_sylvestris': 6, 'Pseudotsuga_menziesii': 7, 'Quercus_spec': 8}\n",
      "first 10 integer labels: [0 5 5 5 0 5 0 5 2 5]\n",
      "first 10 string labels: ['Abies_alba' 'Picea_abies' 'Picea_abies' 'Picea_abies' 'Abies_alba'\n",
      " 'Picea_abies' 'Abies_alba' 'Picea_abies' 'Fagus_sylvatica' 'Picea_abies']\n"
     ]
    }
   ],
   "source": [
    "le = lt.CustomLabelEncoder()\n",
    "le.fit(labels, sorter=lambda x: x.upper())\n",
    "\n",
    "labels_int = le.transform(labels[:10])\n",
    "labels_str = le.inverse_transform(labels_int)\n",
    "\n",
    "label_dir = Path('/home/richard/data/Schiefer/combine/')\n",
    "filename = Path('VGG16_polygon_pred_label_encodings_224_' + str(imgs_path).split('_')[5] + '.pickle')\n",
    "with open(label_dir / filename, 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print('label encodings: {}'.format(le.mapper))\n",
    "print('first 10 integer labels: {}'.format(labels_int))\n",
    "print('first 10 string labels: {}'.format(labels_str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction\n",
    "\n",
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for avgpool layer features 512\n",
    "# model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "  def __init__(self, model):\n",
    "    super(FeatureExtractor, self).__init__()\n",
    "\t\t# Extract VGG-16 Feature Layers\n",
    "    self.features = list(model.features)\n",
    "    self.features = nn.Sequential(*self.features)\n",
    "\t\t# Extract VGG-16 Average Pooling Layer\n",
    "    self.pooling = model.avgpool\n",
    "\t\t# Convert the image into one-dimensional vector\n",
    "    self.flatten = nn.Flatten()\n",
    "\t\t# Extract the first part of fully-connected layer from VGG16\n",
    "    self.fc = model.classifier[0]\n",
    "  \n",
    "  def forward(self, x):\n",
    "\t\t# It will take the input 'x' until it returns the feature vector called 'out'\n",
    "    out = self.features(x)\n",
    "    out = self.pooling(out)\n",
    "    out = self.flatten(out)\n",
    "    out = self.fc(out) \n",
    "    return out \n",
    "\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "new_model = FeatureExtractor(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get FC1 features of the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(tensor):\n",
    "    with torch.no_grad():\n",
    "        feature = new_model(tensor)\n",
    "    feature = concat_tensors(feature)\n",
    "    return feature\n",
    "\n",
    "def concat_tensors(features):\n",
    "    fc = torch.cat(features)\n",
    "    fc = fc.cpu().detach().numpy()\n",
    "    return fc\n",
    "\n",
    "def get_features(tensors):\n",
    "    with torch.no_grad():\n",
    "        features = [model(tensor) for tensor in tqdm(tensors)]\n",
    "    features = concat_tensors(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5146, -3.0128,  1.2858,  ..., -4.5630, -0.6749, -2.4996]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(get_feature(image_tensors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc1 = get_features(image_tensors)\n",
    "# print(fc1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get avgpool features (flattened 7 x 7 x 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pooled_features(tensors):\n",
    "#     features = [model(tensor) for tensor in tqdm(tensors)]\n",
    "#     print(\"done first\")\n",
    "#     features = [torch.flatten(tensor, 1) for tensor in tensors]\n",
    "#     features = concat_tensors(features)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cab2442ace40189e45d53cf0caa14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done first\n",
      "(1126, 150528)\n"
     ]
    }
   ],
   "source": [
    "# fc1 = get_pooled_features(image_tensors)\n",
    "# print(fc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results = {'filename': files,\n",
    "           'features': fc1,\n",
    "           'labels': labels,\n",
    "           'layer_name': 'fc1'}\n",
    "\n",
    "feature_dir = Path('/home/richard/data/Schiefer/combine/')\n",
    "feature_filename = Path('VGG16_polygon_pred_224_' + str(imgs_path).split('_')[5] + '.pickle')\n",
    "Path(feature_dir).mkdir(parents=True, exist_ok=True)\n",
    "with open(feature_dir / feature_filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579d37c0e11f829fd27710afca693474f5bbc510c142a7662cee2b0a86b87b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
