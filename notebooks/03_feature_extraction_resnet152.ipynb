{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import permute\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "import label_tools as lt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Files\n",
    "\n",
    "load pre processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_path = Path('/home/richard/data/Schiefer/feature_extraction/clips/preprocessed_224_clipped_pred_polygon_224/')\n",
    "#imgs_path = Path('/home/richard/data/Schiefer/feature_extraction/clips/preprocessed_224_clipped_pred_square_205/')\n",
    "#imgs_path = Path('/home/richard/data/Schiefer/feature_extraction/clips/preprocessed_224_clipped_gt_polygon_296/')\n",
    "#imgs_path = Path(''/home/richard/data/Schiefer/feature_extraction/clips/preprocessed_224_clipped_gt_square_296/'')\n",
    "\n",
    "imgs_path = Path('/home/richard/data/Schiefer/combine/preprocessed_512_clipped_pred_polygon_1126/')\n",
    "assert imgs_path.is_dir()\n",
    "files = sorted(imgs_path.glob('*.png'))\n",
    "\n",
    "randomizer = np.random.RandomState(seed=99833)\n",
    "randomizer.shuffle(files)\n",
    "\n",
    "assert len(files) == int(str(imgs_path).split('_')[5]) # all files are found\n",
    "print(\"First 10 files are: {}\".format([x.name for x in files[:10]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def alter_image(img_name):\n",
    "    image = Image.open(img_name)\n",
    "    image_tensor = normalize(to_tensor(image)).unsqueeze(0)\n",
    "    image_tensor = image_tensor.reshape(1,3,512,512)\n",
    "    return image_tensor\n",
    "\n",
    "def load_images_as_tensors(paths):\n",
    "    images = [alter_image(image) for image in paths]\n",
    "    return images\n",
    "\n",
    "image_tensors = load_images_as_tensors(files)\n",
    "assert len(image_tensors) == int(str(imgs_path).split('_')[5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting labels from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(files): return [filename.stem.split('_')[4] for filename in files]\n",
    "labels = extract_labels(files)\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels from number to species (of collab)\n",
    "update = {\n",
    "    '4':'Fagus_sylvatica',\n",
    "    '5':'Fraxinus_excelsior',\n",
    "    '6':'Quercus_spec',\n",
    "    '8':'deadwood',\n",
    "    '10':'Abies_alba',\n",
    "    '11':'Larix_decidua',\n",
    "    '12':'Picea_abies',\n",
    "    '13':'Pinus_sylvestris',\n",
    "    '14':'Pseudotsuga_menziesii'\n",
    "}\n",
    "\n",
    "updated_labels = (pd.Series(labels)).map(update)\n",
    "species_labels = list(updated_labels)\n",
    "labels = species_labels\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change labels from number to species\n",
    "# update = {\n",
    "#     '4':'Fagus_sylvatica',\n",
    "#     '8':'deadwood',\n",
    "#     '10':'Abies_alba',\n",
    "#     '12':'Picea_abies'\n",
    "# }\n",
    "\n",
    "# updated_labels = (pd.Series(labels)).map(update)\n",
    "# species_labels = list(updated_labels)\n",
    "# labels = species_labels\n",
    "# print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding\n",
    "\n",
    "Standardize encodings of labels to make analysis easier afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = lt.CustomLabelEncoder()\n",
    "le.fit(labels, sorter=lambda x: x.upper())\n",
    "\n",
    "labels_int = le.transform(labels[:10])\n",
    "labels_str = le.inverse_transform(labels_int)\n",
    "\n",
    "label_dir = Path('/home/richard/data/Schiefer/feature_extraction/labels')\n",
    "filename = Path('ResNet152_polygon_pred_label_encodings_512_' + str(imgs_path).split('_')[5] + '.pickle')\n",
    "with open(label_dir / filename, 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print('label encodings: {}'.format(le.mapper))\n",
    "print('first 10 integer labels: {}'.format(labels_int))\n",
    "print('first 10 string labels: {}'.format(labels_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.transform(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction\n",
    "\n",
    "Load the ResNet152 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2)# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(image_tensor):\n",
    "    # a dict to store the activations\n",
    "    activation = {}\n",
    "    def getActivation(name):\n",
    "        # the hook signature\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # register forward hooks on the layers of choice\n",
    "    h1 = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "\n",
    "    # forward pass -- getting the outputs\n",
    "    out = model(image_tensor)\n",
    "\n",
    "    # detach the hooks\n",
    "    h1.remove()\n",
    "    \n",
    "    feature = torch.squeeze(activation['avgpool'])\n",
    "    feature = torch.unsqueeze(feature,dim=0)\n",
    "    return feature\n",
    "\n",
    "# check\n",
    "feature = get_feature_vector(image_tensors[0])\n",
    "print(feature.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all features of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def concat_tensors(features):\n",
    "    fc = torch.cat(features)\n",
    "    fc = fc.cpu().detach().numpy()\n",
    "    return fc\n",
    "\n",
    "def get_features(image_tensors):\n",
    "    features = [get_feature_vector(tensor) for tensor in tqdm(image_tensors)]\n",
    "    features = concat_tensors(features)\n",
    "    return features\n",
    "\n",
    "fc = get_features(image_tensors)\n",
    "print(fc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'filename': files,\n",
    "           'features': fc,\n",
    "           'labels': labels,\n",
    "           'layer_name': 'fc'}\n",
    "\n",
    "feature_dir = Path('/home/richard/data/Schiefer/feature_extraction/features')\n",
    "feature_filename = Path('ResNet152_polygon_pred_512_' + str(imgs_path).split('_')[5] + '.pickle')\n",
    "print(feature_dir / feature_filename)\n",
    "Path(feature_dir).mkdir(parents=True, exist_ok=True)\n",
    "with open(feature_dir / feature_filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "images_path = '/home/richard/data/Schiefer/pred_polygon_clipped_raster_files/'\n",
    "out_dir = Path(images_path).parent / Path('preprocessed_' + 'None' + '_clahe-denoising_' + 'clipped_pred_' + 'polygon' + '_' + str(204))\n",
    "print(out_dir)\n",
    "\n",
    "print(str(out_dir).split('_')[2])\n",
    "import os\n",
    "os.path.isdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "en_path = '/home/richard/data/Schiefer/label_encodings/effnet_clahe-denoising_polygon_pred.pickle'\n",
    "ident = str(Path(en_path).stem).split('_')[0] + '_' + str(en_path).split('_')[2]\n",
    "print(ident)\n",
    "print(Path(en_path).stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579d37c0e11f829fd27710afca693474f5bbc510c142a7662cee2b0a86b87b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
