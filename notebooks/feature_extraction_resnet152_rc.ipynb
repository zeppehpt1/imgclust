{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import permute\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 files are: ['CFB184_ortho_rgb_0110_preprocessed.png', 'CFB184_ortho_rgb_0107_preprocessed.png', 'CFB184_ortho_rgb_0111_preprocessed.png', 'CFB184_ortho_rgb_0123_preprocessed.png', 'CFB184_ortho_rgb_0105_preprocessed.png', 'CFB184_ortho_rgb_0170_preprocessed.png', 'CFB184_ortho_rgb_0184_preprocessed.png', 'CFB184_ortho_rgb_0231_preprocessed.png', 'CFB184_ortho_rgb_0271_preprocessed.png', 'CFB184_ortho_rgb_0188_preprocessed.png']\n"
     ]
    }
   ],
   "source": [
    "# load pre processed files\n",
    "imgs_path = Path('/home/richard/data/Schiefer/preprocessed_224')\n",
    "assert imgs_path.is_dir()\n",
    "files = sorted(imgs_path.glob('*.png'))\n",
    "\n",
    "randomizer = np.random.RandomState(seed=99833)\n",
    "randomizer.shuffle(files)\n",
    "\n",
    "assert len(files) == 291 # all files are found\n",
    "print(\"First 10 files are: {}\".format([x.name for x in files[:10]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def alter_image(img_name):\n",
    "    image = Image.open(img_name)\n",
    "    image_tensor = normalize(to_tensor(image)).unsqueeze(0)\n",
    "    image_tensor = image_tensor.reshape(1,3,224,224)\n",
    "    return image_tensor\n",
    "\n",
    "def load_images_as_tensors(paths):\n",
    "    images = [alter_image(image) for image in paths]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = load_images_as_tensors(files)\n",
    "assert len(image_tensors) == 291"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction\n",
    "\n",
    "Load the ResNet152 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V2)# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "def get_feature_vector(image_tensor):\n",
    "    # a dict to store the activations\n",
    "    activation = {}\n",
    "    def getActivation(name):\n",
    "        # the hook signature\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # register forward hooks on the layers of choice\n",
    "    h1 = model.avgpool.register_forward_hook(getActivation('avgpool'))\n",
    "\n",
    "    # forward pass -- getting the outputs\n",
    "    out = model(image_tensor)\n",
    "\n",
    "    # detach the hooks\n",
    "    h1.remove()\n",
    "    \n",
    "    feature = torch.squeeze(activation['avgpool'])\n",
    "    feature = torch.unsqueeze(feature,dim=0)\n",
    "    return feature\n",
    "\n",
    "# check\n",
    "feature = get_feature_vector(image_tensors[0])\n",
    "print(feature.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all features of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_tensors(features):\n",
    "    fc = torch.cat(features)\n",
    "    fc = fc.cpu().detach().numpy()\n",
    "    return fc\n",
    "\n",
    "def get_features(image_tensors):\n",
    "    features = [get_feature_vector(tensor) for tensor in image_tensors]\n",
    "    features = concat_tensors(features)\n",
    "    return features\n",
    "\n",
    "fc = get_features(image_tensors)\n",
    "print(fc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'filename': files,\n",
    "           'features': fc,\n",
    "           'layer_name': 'fc'}\n",
    "\n",
    "feature_dir = imgs_path.parent / 'features'\n",
    "Path(feature_dir).mkdir(parents=True, exist_ok=True)\n",
    "with open(feature_dir / 'ResNet152_feature_std_224.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579d37c0e11f829fd27710afca693474f5bbc510c142a7662cee2b0a86b87b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
