{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.exposure as skie\n",
    "import skimage\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image,ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/Schiefer/CFB184_ortho_rgb_0003.png'\n",
    "#img_path = '/home/richard/data/Schiefer/CFB184clipped_raster_files/CFB184_ortho_rgb_0003.png'\n",
    "img = plt.imread(img_path)\n",
    "#img = skimage.color.rgb2gray(img) # preserves luminance of img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramm normalization\n",
    "\n",
    "- with CLAHE\n",
    "  - Two benefits: normalize brightness, reduce differences between darker and light images\n",
    "  - enhance contrast of image (stronger responses in conv layers)\n",
    "\n",
    "Kinda only useful for square images otherwise black pixels are appearing too often, but still brightness is normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img): #displays image next to a histogram\n",
    "    # Display the image.\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,\n",
    "                                   figsize=(12, 3))\n",
    "\n",
    "    ax1.imshow(img, cmap=plt.cm.gray)\n",
    "    ax1.set_axis_off()\n",
    "\n",
    "    # Display the histogram.\n",
    "    ax2.hist(img.ravel(), lw=0, bins=256)\n",
    "    ax2.set_xlim(0, img.max())\n",
    "    ax2.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast Limited Adaptive Histogram Equalization (CLAHE) applied\n",
    "show(skie.equalize_adapthist(img))\n",
    "# under the hood works rescale_intensity, equalize_adapthist,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = skie.equalize_adapthist(img)\n",
    "print(type(new))\n",
    "PIL_image = Image.fromarray((new * 255).astype(np.uint8))\n",
    "plt.imshow(PIL_image)\n",
    "print(PIL_image.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize images\n",
    "\n",
    "VGG16 and ResNet default size = 224. Use this size for square crowns. For whole polygons resize images to 448. So they can be directly fed into the CNN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_crops_path = '/home/richard/data/Schiefer/CFB184clipped_raster_files/'\n",
    "polygon_crops_path = '/home/richard/data/Schiefer/clipped_raster_files_polygon/'\n",
    "\n",
    "print(Path(square_crops_path).parent / 'preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, expected_size):\n",
    "    desired_size = expected_size\n",
    "    delta_width = desired_size - img.size[0]\n",
    "    delta_height = desired_size - img.size[1]\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(img, padding)\n",
    "\n",
    "def resize_with_padding(img, expected_size):\n",
    "    img.thumbnail((expected_size[0], expected_size[1]))\n",
    "    # print(img.size)\n",
    "    delta_width = expected_size[0] - img.size[0]\n",
    "    delta_height = expected_size[1] - img.size[1]\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(img, padding)\n",
    "\n",
    "def get_png_file_names(file_dir):\n",
    "    files = glob.glob(file_dir + '*.png')\n",
    "    print(\"num files\",len(files))\n",
    "    return files\n",
    "\n",
    "def preprocess_images(images_path,expected_size):\n",
    "    out_dir = Path(images_path).parent / Path('preprocessed_' + str(expected_size)) \n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_list = get_png_file_names(images_path)\n",
    "    for img in file_list:\n",
    "        file_name = Path(img).stem\n",
    "        img = plt.imread(img)\n",
    "        # normalize brightness\n",
    "        processed_img = skie.equalize_adapthist(img)\n",
    "        PIL_image = Image.fromarray((processed_img * 255).astype(np.uint8))\n",
    "        # resize\n",
    "        PIL_image = resize_with_padding(PIL_image,(expected_size,expected_size))\n",
    "        PIL_image.save(str(out_dir) + '/' + str(file_name) + '_preprocessed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_images(polygon_crops_path,224)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579d37c0e11f829fd27710afca693474f5bbc510c142a7662cee2b0a86b87b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
